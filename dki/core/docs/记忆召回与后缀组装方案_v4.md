# DKI v4 — 记忆召回与后缀组装方案

## 可行性分析与完整实施方案

---

## 一、核心思想提取

### 1.1 方案定位

从 `后缀构造方案.md` 的讨论中提炼出的核心设计原则:

| 原则                         | 说明                                                                |
| ---------------------------- | ------------------------------------------------------------------- |
| **Summary 不是事实**         | Summary 仅作为"导航标志"，帮助模型判断是否需要查询完整事实          |
| **Function Call 是事实通道** | 模型可以主动请求补充事实，而不是被迫在不完整信息上编造回答          |
| **准确性优先**               | 性能留给硬件，架构专注于不 hallucinate                              |
| **风险单向化**               | Summary 错了 → 多查一次；而非 Summary 错了 → 回答错误               |
| **认知同构**                 | 系统行为类似人类专家: 大概了解 → 发现细节重要 → 翻原始资料 → 下判断 |

### 1.2 信息分层模型 (v4)

```
┌─────────────────────────────────────────────────────────────────┐
│  层级  │  内容              │  注入方式       │  认知类比       │
├────────┼───────────────────┼────────────────┼────────────────┤
│  L0    │  偏好 (Preference) │  K/V 负位置    │  人格/性格     │ ← 不变
│  L1    │  History List     │  Token 域后缀  │  工作记忆索引  │ ← 新增
│  L2    │  可信+推理限定提示  │  Token 域正文  │  认知规约      │ ← 新增
│  L3    │  用户 Query       │  Token 域正文  │  当前任务      │ ← 位置调整
│  L4    │  Function Call    │  追加事实段    │  查阅资料      │ ← 新增
└─────────────────────────────────────────────────────────────────┘
```

### 1.3 与现有策略的对比

| 维度          | 现有 Stable            | v4 方案                                              |
| ------------- | ---------------------- | ---------------------------------------------------- |
| 偏好注入      | K/V 负位置 (α=0.3-0.5) | **不变**                                             |
| 历史召回      | 固定 N 轮近期消息      | 多信号融合 (关键词+权重 + 指代解析 + 向量相似度)     |
| 历史注入      | 全量 message 平铺      | 逐消息判断: 超阈值 →summary+trace_id, 阈值内 → 原文  |
| 模型指导      | "请参考以上历史"       | 可信+推理限定提示 (禁止基于 summary 推理)            |
| 大历史/长消息 | 截断丢弃               | Summary 压缩 + function call 按需拉取 (offset+limit) |
| function call | ❌ 无                  | ✅ 应用层函数，通过 trace_id 检索原文                |
| context 爆炸  | 截断硬限制             | 动态预算 + 逐消息 summary + 按需拉取                 |

---

## 二、完整召回与组装流程

### 2.1 总体流程图

```
用户输入 (query)
    │
    ▼
┌─────────────────────────────────────────────┐
│           Phase 1: 多信号召回                  │
│                                              │
│  ┌──────────┐  ┌──────────┐  ┌───────────┐  │
│  │关键词+权重│  │ 指代解析  │  │ 向量相似度 │  │
│  │ 检索     │  │ (已有)    │  │ (已有FAISS)│  │
│  └────┬─────┘  └────┬─────┘  └────┬──────┘  │
│       └──────────┬──┴─────────────┘          │
│                  ▼                            │
│       合并 + 去重 + 按相关性排序               │
│                  ▼                            │
│       + 补充固定 N 轮近期会话                  │
│                  ▼                            │
│       完整关联消息列表                         │
└──────────────────┬──────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────┐
│         Phase 2: 逐消息阈值判断               │
│                                              │
│  for msg in messages:                        │
│    tokens = tokenize(msg.content)            │
│    if tokens > threshold:                    │
│      → summary(msg) + trace_id              │
│    else:                                     │
│      → 保留原始消息                           │
└──────────────────┬──────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────┐
│         Phase 3: 构造器组装                    │
│                                              │
│  按模型适配构造:                               │
│    history_list                               │
│    + 可信+推理限定提示                         │
│    + 用户 query                               │
│                                              │
│  偏好: K/V 负位置注入 (不变)                   │
└──────────────────┬──────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────┐
│         Phase 4: 推理 + Function Call 循环    │
│                                              │
│  模型推理 → 检查输出                          │
│    ├── 无 fact_call → 返回结果 ✅             │
│    └── 有 fact_call(trace_id, offset, limit) │
│         → FactRetriever 检索原文              │
│         → 追加 [FACT_SEGMENT] 到 prompt       │
│         → 重新推理 (最多 max_rounds 轮)       │
└─────────────────────────────────────────────┘
```

### 2.2 Phase 1: 多信号召回

#### 2.2.1 三路信号

| 信号            | 来源                              | 作用                                  | 系统现有能力                                |
| --------------- | --------------------------------- | ------------------------------------- | ------------------------------------------- |
| **关键词+权重** | jieba 分词 + TF-IDF/TextRank 权重 | 精确匹配事实性关键词 (人名/地名/数字) | MemoryRepository.search_by_content() 可扩展 |
| **指代解析**    | ReferenceResolver (已有)          | 解析"刚才""上次""那个" → 确定召回范围 | ✅ 已有, recall_turns 输出                  |
| **向量相似度**  | EmbeddingService + FAISS (已有)   | 语义级匹配                            | ✅ MemoryRouter.search()                    |

#### 2.2.2 召回合并策略

```python
def recall(query, session_id, user_id):
    # 1. 指代解析 → 确定召回范围
    ref_result = reference_resolver.resolve(query)
    recall_turns = ref_result.recall_turns or default_recall_turns

    # 2. 分词 + 关键词提取 (带权重)
    keywords = jieba_extract_keywords(query, topK=5, withWeight=True)

    # 3. 关键词检索 (从会话历史中匹配)
    keyword_hits = search_by_keywords(session_id, keywords)

    # 4. 向量相似度检索
    vector_hits = memory_router.search(query, top_k=top_k)

    # 5. 合并 + 去重 (按 message_id)
    merged = merge_and_deduplicate(keyword_hits, vector_hits)

    # 6. 按相关性排序 (综合关键词权重 + 向量分数)
    sorted_messages = rank_by_relevance(merged)

    # 7. 补充固定轮数近期会话 (保证上下文连续性)
    recent = get_recent_turns(session_id, n=min_recent_turns)

    # 8. 合并 (近期消息优先, 去重)
    final_list = merge_recent_and_recalled(recent, sorted_messages)

    return final_list  # 完整关联消息列表
```

#### 2.2.3 关键词+权重检索说明

现有 `MemoryRepository.search_by_content()` 是简单 ILIKE 模糊匹配。
v4 需要扩展为 **带权重的关键词检索**:

-   使用 `jieba.analyse.extract_tags(query, topK=5, withWeight=True)` 提取关键词及权重
-   对每个关键词在会话历史中做匹配
-   命中分数 = Σ(匹配关键词的权重)
-   可在应用层实现，无需修改数据库

### 2.3 Phase 2: 逐消息阈值判断

**核心逻辑**: 遍历召回的消息列表，根据每条消息的 token 数决定保留或摘要。

```python
def process_messages(messages, context_budget, tokenizer, summarizer):
    """
    逐消息判断: 超过阈值 → summary + trace_id, 否则保留原文
    同时累计 token 消耗，超出总预算时停止
    """
    items = []
    used_tokens = 0

    for msg in messages:
        msg_tokens = tokenizer.count_tokens(msg.content)

        if msg_tokens > per_message_threshold:
            # 超阈值: 生成 summary + 保留 trace_id
            summary_text = summarizer.summarize(msg.content, max_tokens=summary_max_tokens)
            summary_tokens = tokenizer.count_tokens(summary_text)

            if used_tokens + summary_tokens > context_budget:
                break  # 预算耗尽

            items.append(HistoryItem(
                type="summary",
                content=summary_text,
                trace_id=msg.message_id,  # 用于 function call 溯源
                role=msg.role,
                token_count=summary_tokens,
                confidence="medium",       # summary 的置信标记
            ))
            used_tokens += summary_tokens
        else:
            # 阈值内: 保留完整原文
            if used_tokens + msg_tokens > context_budget:
                break  # 预算耗尽

            items.append(HistoryItem(
                type="message",
                content=msg.content,
                trace_id=msg.message_id,
                role=msg.role,
                token_count=msg_tokens,
                confidence="high",         # 原文，置信度高
            ))
            used_tokens += msg_tokens

    return items, used_tokens
```

**阈值计算**:

```
per_message_threshold = config.recall.summary.per_message_threshold  # 如 200 tokens
context_budget = context_window - preference_tokens - instruction_tokens - query_tokens - generation_reserve
```

### 2.4 Phase 3: 构造器组装

**按模型适配构造最终 prompt**, 输出结构:

```
┌──────────────────────────────────────────────────────────┐
│ [History List]                                            │
│                                                           │
│ [SUMMARY trace_id="msg-001" conf=medium]                 │
│ - 用户讨论了旅行计划，提到想去云南...                        │
│ - 本摘要可能缺失: 具体日期、同行人数                         │
│ [/SUMMARY]                                                │
│                                                           │
│ 用户: 那个餐厅叫什么来着？                                  │ ← 原文 (短消息)
│ 助手: 您提到的是"绿野仙踪"素食餐厅。                        │ ← 原文
│                                                           │
│ [SUMMARY trace_id="msg-005" conf=medium]                 │
│ - 助手详细介绍了素食餐厅菜单...                             │
│ - 本摘要可能缺失: 具体菜品价格                              │
│ [/SUMMARY]                                                │
│                                                           │
│ 用户: 对，就是那个，营业时间是？                             │ ← 原文 (最近消息)
│                                                           │
│ [可信+推理限定]                                             │
│ 以上 [SUMMARY] 为摘要，非完整事实记录。                      │
│ 若回答需要精确原话/数据/时间顺序/因果关系，                   │
│ 且摘要中未明确包含，                                        │
│ 请调用 retrieve_fact(trace_id="...", offset=0, limit=5)   │
│ 获取原始记录。不得基于摘要进行推理。                          │
│ [/可信+推理限定]                                            │
│                                                           │
│ 用户当前问题: 营业时间是几点？                               │
└──────────────────────────────────────────────────────────┘
```

### 2.5 Phase 4: Function Call 循环

**Function Call 是一个应用层的简单函数**, 不依赖模型原生 function call 能力:

```python
async def execute_with_fact_loop(plan, max_new_tokens, temperature):
    """推理 + 事实补充循环"""
    prompt = plan.final_input
    total_fact_tokens = 0

    for round_idx in range(max_fact_rounds):
        # 推理
        output = model.generate(prompt, max_new_tokens, temperature)

        # 检查输出是否包含 fact_call
        fact_request = prompt_formatter.detect_fact_request(output.text)

        if fact_request is None:
            return output  # 不需要补充事实, 直接返回 ✅

        # 检索事实 (通过 trace_id, 支持 offset+limit)
        fact_response = fact_retriever.retrieve(
            trace_id=fact_request.trace_id,
            session_id=plan.session_id,
            offset=fact_request.offset,
            limit=fact_request.limit,
        )

        # 格式化事实段落
        fact_text = prompt_formatter.format_fact_segment(fact_response)
        fact_tokens = tokenizer.count_tokens(fact_text)
        total_fact_tokens += fact_tokens

        # 检查事实总量是否超限
        if total_fact_tokens > max_fact_tokens:
            break  # 事实量已达上限, 强制结束

        # 追加事实段落到 prompt, 继续推理
        prompt = prompt + "\n" + fact_text + "\n" + "请基于以上补充事实回答用户问题。"

    return output  # 达到最大轮次
```

---

## 三、数据结构设计

### 3.1 HistoryItem — 历史条目

```python
@dataclass
class HistoryItem:
    """可见区历史条目 (可以是原始消息或 summary)"""
    type: str              # "summary" | "message"
    content: str           # 文本内容 (summary 文本 或 原始消息)
    trace_id: str          # 可溯源 ID (message_id, 用于 function call 检索原文)
    role: Optional[str]    # "user" | "assistant"
    token_count: int       # token 数
    confidence: str        # "high" (原文) | "medium" (summary) | "low"
```

### 3.2 RecallResult — 召回结果

```python
@dataclass
class RecallResult:
    """多信号召回结果"""
    messages: List[ChatMessage]       # 召回的完整消息列表 (已排序)
    keyword_hits: int                 # 关键词命中数
    vector_hits: int                  # 向量命中数
    reference_scope: Optional[str]    # 指代解析范围
    recent_turns_added: int           # 补充的近期轮数
```

### 3.3 AssembledSuffix — 组装后的后缀

```python
@dataclass
class AssembledSuffix:
    """组装完成的后缀"""
    text: str                       # 最终拼装文本
    items: List[HistoryItem]        # 组成条目列表
    total_tokens: int               # 总 token 数
    message_count: int              # 原文消息数量
    summary_count: int              # summary 数量
    has_fact_call_instruction: bool  # 是否包含 function call 指导
    trace_ids: List[str]            # 所有 trace_id 列表 (用于 fact retriever 查询范围)
```

### 3.4 FactRequest / FactResponse — 事实请求/响应

```python
@dataclass
class FactRequest:
    """模型发出的事实检索请求"""
    trace_id: str           # 要查询的消息 trace_id
    query: Optional[str]    # 查询主题 (可选, 用于精准定位)
    offset: int = 0         # 分页偏移
    limit: int = 5          # 每次返回条数

@dataclass
class FactResponse:
    """事实检索响应 (mini-batch)"""
    messages: List[Dict[str, str]]  # 原始消息列表 [{role, content, timestamp}]
    trace_id: str                   # 对应的 trace_id
    total_count: int                # 总条目数
    offset: int                     # 当前偏移
    has_more: bool                  # 是否有更多
```

---

## 四、核心组件设计

### 4.1 模块结构

```
dki/core/recall/
├── __init__.py              # 包入口
├── recall_config.py         # 配置数据结构
├── multi_signal_recall.py   # 多信号召回器 (关键词+指代+向量)
├── suffix_builder.py        # 后缀组装器 (逐消息阈值 + 组装)
├── fact_retriever.py        # 事实检索器 (trace_id + offset/limit)
└── prompt_formatter.py      # 模型特定提示格式化器
```

### 4.2 MultiSignalRecall — 多信号召回器

```python
class MultiSignalRecall:
    """
    多信号融合召回器

    三路信号:
    1. 关键词+权重: jieba 分词 → TF-IDF 关键词 → 数据库匹配
    2. 指代解析: ReferenceResolver (已有) → 确定召回范围
    3. 向量相似度: EmbeddingService + FAISS (已有) → 语义匹配

    合并策略: 去重 + 综合排序 + 补充固定近期轮数
    """

    def __init__(
        self,
        config: RecallConfig,
        reference_resolver: ReferenceResolver,   # 已有
        memory_router: Optional[MemoryRouter],    # 已有 (向量检索)
        tokenizer: Any,                           # 分词器 (jieba)
    ):
        ...

    def recall(
        self,
        query: str,
        session_id: str,
        db_session: Any,           # 数据库 session
        max_results: int = 50,     # 最大返回消息数
    ) -> RecallResult:
        """
        执行多信号召回

        1. 指代解析 → 确定范围
        2. 关键词+权重检索
        3. 向量相似度检索
        4. 合并去重排序
        5. 补充固定近期轮数
        """
        ...
```

### 4.3 SuffixBuilder — 后缀组装器

```python
class SuffixBuilder:
    """
    后缀组装器

    输入: 召回的消息列表 + context 预算
    输出: 组装好的后缀文本 (history list + 限定提示 + query)

    核心逻辑:
    1. 遍历消息列表
    2. 逐条判断: token > 阈值 → summary + trace_id, 否则保留原文
    3. 累计 token, 超预算停止
    4. 按模型适配格式化
    5. 追加可信+推理限定提示
    6. 追加用户 query
    """

    def __init__(
        self,
        config: RecallConfig,
        prompt_formatter: PromptFormatter,   # 模型特定格式化器
        summarizer: Any,                     # 第三方 summary 工具
        tokenizer: Any,                      # 用于 token 计数
    ):
        ...

    def build(
        self,
        query: str,
        recalled_messages: List[ChatMessage],  # 召回的消息列表
        context_budget: int,                   # 可用 token 预算
    ) -> AssembledSuffix:
        """组装后缀"""
        ...
```

### 4.4 FactRetriever — 事实检索器

```python
class FactRetriever:
    """
    事实检索器 (function call 后端)

    通过 trace_id 检索原始消息内容。
    支持 offset + limit 分块，用于处理长文本消息。

    trace_id → 数据库查询 → 返回原始消息的分页结果

    最大返回量由 config.recall.fact_call.max_fact_tokens 限制
    """

    def retrieve(
        self,
        trace_id: str,
        session_id: str,
        db_session: Any,
        offset: int = 0,
        limit: int = 5,
    ) -> FactResponse:
        """
        检索指定 trace_id 的原始消息

        如果 trace_id 对应的是一条长消息，
        则按 offset+limit 分块返回消息文本片段。

        如果 trace_id 对应的是一组会话轮次 (summary 覆盖多轮),
        则按 offset+limit 返回原始消息列表。
        """
        ...
```

### 4.5 PromptFormatter — 模型特定提示格式化器

**需要模型特定拼装器的判断: ✅ 需要**

理由:

1. **Function call 触发格式**因模型而异 — DeepSeek 用特殊 token, GLM 用 observation 标记, 通用模型用文本标记
2. **提示语措辞**影响小模型 (7B/8B) 的遵从度
3. 但采用 **"通用基类 + 模型特化覆盖"** 模式，工作量可控

```python
class PromptFormatter(ABC):
    """
    模型特定提示格式化器 (抽象基类)

    职责:
    1. 格式化 history list 中的 summary 和 message 条目
    2. 生成可信+推理限定提示 (含 function call 调用指令)
    3. 格式化 function call 返回的事实段落
    4. 从模型输出中检测 function call 触发
    """

    @abstractmethod
    def format_summary_item(self, item: HistoryItem, language: str) -> str:
        """格式化 summary 条目 (含 trace_id + 置信标记)"""

    @abstractmethod
    def format_message_item(self, item: HistoryItem, language: str) -> str:
        """格式化原文消息条目"""

    @abstractmethod
    def format_constraint_instruction(self, trace_ids: List[str], language: str) -> str:
        """生成可信+推理限定提示"""

    @abstractmethod
    def format_fact_segment(self, response: FactResponse, language: str) -> str:
        """格式化事实段落 (function call 返回)"""

    @abstractmethod
    def detect_fact_request(self, model_output: str) -> Optional[FactRequest]:
        """从模型输出中检测 function call 请求"""


class GenericFormatter(PromptFormatter):
    """
    通用格式化器 (默认, 纯文本标记)

    适用于任何模型, 不依赖特殊 token。

    Function Call 触发格式:
      retrieve_fact(trace_id="msg-xxx", offset=0, limit=5)

    检测: 正则匹配 retrieve_fact\(.*?\)
    """

class DeepSeekFormatter(PromptFormatter):
    """
    DeepSeek 格式化器

    利用 DeepSeek 的 function call 特殊 token:
      <｜tool▁calls▁begin｜><｜tool▁call▁begin｜>function_name
      {"trace_id": "...", "offset": 0, "limit": 5}
      <｜tool▁call▁end｜><｜tool▁calls▁end｜>

    在 system prompt 中注册 retrieve_fact 工具定义。
    触发更可靠 (模型原生支持)。
    """

class GLMFormatter(PromptFormatter):
    """ChatGLM 格式化器 — 使用 <|tool_call|> / <|observation|> 格式"""
```

**工厂函数** (通过配置或模型名自动选择):

```python
def create_formatter(model_name: str, language: str = "cn") -> PromptFormatter:
    name = model_name.lower()
    if "deepseek" in name:
        return DeepSeekFormatter(language=language)
    elif "glm" in name or "chatglm" in name:
        return GLMFormatter(language=language)
    else:
        return GenericFormatter(language=language)
```

---

## 五、第三方工具方案

### 5.1 分词器 (Tokenizer) — 两个用途

v4 方案需要两类 "分词":

| 用途           | 目的                                | 推荐方案                           |
| -------------- | ----------------------------------- | ---------------------------------- |
| **Token 计数** | 精确计算消息/prompt 占用的 token 数 | 使用 **模型自带 tokenizer** (已有) |
| **关键词提取** | 从用户 query 中提取带权重的关键词   | 使用 **jieba**                     |

#### 5.1.1 Token 计数: 直接复用模型 tokenizer

系统已有 `BaseModelAdapter.tokenizer`，可直接用于精确 token 计数:

```python
# 已有能力 — 无需新增
tokens = model_adapter.tokenizer.encode(text)
token_count = len(tokens)
```

当 tokenizer 不可用时 (如离线分析场景)，可使用 `tiktoken` 作为 fallback:

```python
# pip install tiktoken
import tiktoken
enc = tiktoken.get_encoding("cl100k_base")  # GPT-4 系列编码
token_count = len(enc.encode(text))
```

> **结论**: Token 计数不需要额外第三方工具，复用已有 tokenizer 即可。

#### 5.1.2 关键词提取: jieba

```python
# pip install jieba
import jieba.analyse

# TF-IDF 方式提取关键词 (带权重)
keywords = jieba.analyse.extract_tags(
    query,
    topK=5,
    withWeight=True,
    allowPOS=('n', 'nr', 'ns', 'nt', 'nz', 'v', 'vn')  # 名词+动词
)
# 返回: [("素食", 0.85), ("餐厅", 0.72), ("营业时间", 0.68)]

# TextRank 方式 (基于图排序, 更适合长文本)
keywords = jieba.analyse.textrank(
    query,
    topK=5,
    withWeight=True,
)
```

**为什么选 jieba**:

-   中文分词事实标准，社区活跃，文档完善
-   内置 TF-IDF 和 TextRank 两种关键词提取算法
-   支持自定义词典 (可加入领域词汇)
-   轻量，不需要 GPU
-   `pip install jieba` 即可

**备选**:

-   `pkuseg` — 北大，分词精度更高，但较重
-   `HanLP` — 功能全面 (NER/POS/依存分析)，但对本场景过重
-   `LAC` (百度) — 速度快，但生态不如 jieba

### 5.2 Summary 工具

#### 5.2.1 推荐方案: 分两个阶段

| 阶段                   | 策略                 | 工具                | 适用场景                       |
| ---------------------- | -------------------- | ------------------- | ------------------------------ |
| **Phase 1** (先实现)   | 抽取式 (extractive)  | jieba + 自定义规则  | 速度快，可预测，不需要额外模型 |
| **Phase 2** (后续升级) | 生成式 (abstractive) | 调用 LLM 自身做摘要 | 质量最高，但增加一次推理延迟   |

#### 5.2.2 Phase 1: 抽取式 summary (jieba + 规则)

**核心思想**: 不生成新文本，从原文中 **提取关键句**。

```python
import jieba.analyse

def extractive_summarize(text: str, max_tokens: int = 150) -> str:
    """
    抽取式摘要

    1. 按句子切分
    2. jieba.analyse.textrank 对每句打分
    3. 选取得分最高的句子
    4. 按原文顺序排列
    5. 截断到 max_tokens
    6. 添加 epistemic marker
    """
    # 切句
    sentences = re.split(r'[。！？\n]', text)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 5]

    if not sentences:
        return text[:max_tokens]  # fallback

    # TextRank 打分
    keywords = jieba.analyse.textrank(text, topK=20, withWeight=True)
    keyword_dict = dict(keywords)

    # 为每个句子计算分数
    scored = []
    for i, sent in enumerate(sentences):
        words = jieba.lcut(sent)
        score = sum(keyword_dict.get(w, 0) for w in words)
        scored.append((i, sent, score))

    # 选取 top 句子
    scored.sort(key=lambda x: x[2], reverse=True)
    selected = sorted(scored[:5], key=lambda x: x[0])  # 恢复原文顺序

    summary = "。".join(s[1] for s in selected)

    # 截断
    if token_count(summary) > max_tokens:
        summary = truncate_to_tokens(summary, max_tokens)

    return summary
```

**优点**: 速度极快 (~1ms)，不需要额外模型，输出可预测
**缺点**: 不够"智能"，可能遗漏隐含信息

#### 5.2.3 Phase 2: LLM 生成式 summary (后续升级)

直接调用 DKI 系统中已有的 LLM 做摘要:

```python
async def llm_summarize(text: str, max_tokens: int, model_adapter) -> str:
    """
    调用 LLM 生成摘要

    关键: prompt 中明确约束:
    - 这是摘要，不是事实
    - 不确定处必须标注
    - 不得推理、不得补全
    """
    prompt = f"""请将以下对话内容压缩为不超过{max_tokens}字的摘要。
要求:
- 仅提取事实性陈述，不得推理或补充
- 标注不确定或可能遗漏的信息
- 使用"提到了""讨论了"等不确定措辞

原文:
{text}

摘要:"""

    output = model_adapter.generate(prompt, max_new_tokens=max_tokens)
    return output.text
```

**优点**: 中文摘要质量最高，语义理解准确
**缺点**: 每次 summary 需要一次推理 (~100-500ms)

#### 5.2.4 其他第三方 summary 库 (备选)

| 库                      | 语言支持                      | 方式                              | 是否推荐              |
| ----------------------- | ----------------------------- | --------------------------------- | --------------------- |
| `sumy`                  | 英文为主，中文需 jieba 预处理 | extractive (TextRank/LSA/LexRank) | ⚠ 对中文支持一般      |
| `transformers` pipeline | 多语言                        | abstractive (mT5/mBART)           | ⚠ 需要额外模型 (~1GB) |
| `langchain`             | 多语言                        | 基于 LLM 的链式摘要               | ⚠ 过重，依赖多        |
| `paddle-nlp`            | 中文优秀                      | extractive + abstractive          | ⚠ 依赖 PaddlePaddle   |

> **结论**: Phase 1 用 `jieba` + 自定义规则 (最轻量)，Phase 2 直接调用 LLM (最高质量)。
> 不建议引入 `sumy` 或 `transformers` 等额外模型依赖，因为系统已有 LLM 可复用。

### 5.3 依赖汇总

```
# 新增依赖 (仅 1 个)
jieba>=0.42.1        # 中文分词 + 关键词提取

# 已有依赖 (无需新增)
sentence-transformers  # EmbeddingService (向量检索)
faiss-cpu             # MemoryRouter (FAISS 索引)
```

> **只需新增 `jieba` 一个依赖。** Token 计数复用模型 tokenizer，summary 复用 jieba + LLM。

---

## 六、配置设计

```yaml
dki:
    # ============ 记忆召回策略 (v4) ============
    recall:
        enabled: true
        strategy: "summary_with_fact_call" # summary_with_fact_call | flat_history (旧)

        # 多信号召回
        signals:
            keyword_enabled: true # 关键词+权重检索
            keyword_topk: 5 # 提取关键词数量
            keyword_method: "tfidf" # tfidf | textrank
            vector_enabled: true # 向量相似度检索
            vector_top_k: 10 # 向量检索返回数
            vector_threshold: 0.5 # 向量相似度阈值
            reference_enabled: true # 指代解析 (已有 ReferenceResolver)

        # 动态 History 预算
        budget:
            generation_reserve: 512 # 生成预留 tokens
            instruction_reserve: 150 # 限定提示预留 tokens
            min_recent_turns: 2 # 至少补充的近期完整轮次
            max_recent_turns: 5 # 最多补充的近期完整轮次

        # 逐消息 Summary 阈值
        summary:
            per_message_threshold: 200 # 单条消息超过此 token 数 → summary
            max_tokens_per_summary: 150 # 每条 summary 最大 tokens
            strategy: "extractive" # extractive | llm
            # extractive 使用 jieba TextRank
            # llm 调用系统 LLM 生成摘要 (更准, 更慢)

        # Function Call (事实补充)
        fact_call:
            enabled: true
            max_rounds: 3 # 最大事实补充轮次
            max_fact_tokens: 800 # 事实段落总 token 上限
            batch_size: 5 # 每次返回的消息数 (offset+limit)

        # 提示格式化器
        prompt_formatter: "auto" # auto | generic | deepseek | glm
```

---

## 七、对现有系统的修改清单

### 7.1 不需要修改的模块

| 模块                    | 说明                                                                     |
| ----------------------- | ------------------------------------------------------------------------ |
| `dki.models.*`          | 模型适配器完全不变                                                       |
| `dki.database.*`        | 数据层完全不变 (ConversationRepository 已有 get_recent / get_by_session) |
| `dki.cache.*`           | 缓存层完全不变                                                           |
| `dki.core.components.*` | MIS / Gating / Position / Budget 等全部不变                              |
| `dki.core.injection.*`  | Full Attention / Engram 保留但不再作为默认路径                           |

### 7.2 新增模块

| 文件                                     | 职责                                 | 预估行数 |
| ---------------------------------------- | ------------------------------------ | -------- |
| `dki/core/recall/__init__.py`            | 包入口 + 导出                        | ~30      |
| `dki/core/recall/recall_config.py`       | 配置数据结构 + HistoryItem 等        | ~80      |
| `dki/core/recall/multi_signal_recall.py` | 多信号召回器                         | ~150     |
| `dki/core/recall/suffix_builder.py`      | 后缀组装器 (逐消息阈值 + 组装)       | ~200     |
| `dki/core/recall/fact_retriever.py`      | 事实检索器 (trace_id + offset/limit) | ~100     |
| `dki/core/recall/prompt_formatter.py`    | 模型格式化器 (Generic + DeepSeek)    | ~250     |

### 7.3 修改模块

| 文件                                    | 修改点                                        | 预估行数变化 |
| --------------------------------------- | --------------------------------------------- | ------------ |
| `config/config.yaml`                    | 新增 `dki.recall` 配置段                      | +35          |
| `dki/core/dki_system.py`                | `chat()` 中增加 recall_v4 分支                | ~80 行修改   |
| `dki/core/plugin/injection_planner.py`  | `build_plan()` 使用新召回器 + 组装器          | ~50 行修改   |
| `dki/core/plugin/injection_executor.py` | 增加 fact call 循环                           | ~70 行修改   |
| `dki/core/plugin/injection_plan.py`     | 增加 `assembled_suffix`, `fact_rounds` 等字段 | ~25 行修改   |

### 7.4 新增依赖

```
jieba>=0.42.1
```

---

## 八、实施步骤

### Phase 1: 核心组件 (不影响现有系统运行)

```
Step 1.1: pip install jieba; 添加到 requirements.txt
Step 1.2: 创建 dki/core/recall/ 目录
Step 1.3: 实现 recall_config.py (数据结构)
Step 1.4: 实现 prompt_formatter.py (GenericFormatter + DeepSeekFormatter)
Step 1.5: 实现 multi_signal_recall.py (多信号召回器)
Step 1.6: 实现 suffix_builder.py (逐消息阈值 + 组装)
Step 1.7: 实现 fact_retriever.py (trace_id 检索)
```

### Phase 2: 集成到演示系统 (DKISystem)

```
Step 2.1: 修改 config.yaml 添加 recall 配置
Step 2.2: 修改 DKISystem.chat() — 增加 recall_v4 分支
Step 2.3: 实现 fact call 循环逻辑 (在 DKISystem 中)
```

### Phase 3: 集成到插件系统 (DKIPlugin)

```
Step 3.1: 修改 InjectionPlan 增加字段
Step 3.2: 修改 InjectionPlanner.build_plan() 使用新召回 + 组装
Step 3.3: 修改 InjectionExecutor 增加 fact call 循环
```

---

## 九、可行性结论

### ✅ 方案合理性

1. **多信号召回** (关键词+指代+向量) 是业界标准的混合检索方案，各信号互补
2. **逐消息阈值 summary** 比分组 summary 更精细、可预测，且保留了 trace_id 溯源能力
3. **Function call 应用层实现** 不依赖模型原生能力，通过文本标记+正则检测，100% 可控
4. **offset+limit 分块** 是处理长文本的标准模式，天然支持 mini-batch 事实拉取
5. **只需新增 jieba 一个依赖**，分词/关键词/summary 全部通过它解决，token 计数复用已有 tokenizer

### ✅ 对现有系统的影响

-   **偏好注入完全不变** (K/V 负位置，最稳定的部分)
-   **新增模块独立** (dki/core/recall/)，不影响已有代码运行
-   **通过配置切换** — `recall.strategy` 可在 `flat_history` (旧) 和 `summary_with_fact_call` (新) 之间切换
-   **修改量可控** — ~260 行修改 + ~810 行新增

### ✅ 退路

-   关闭 `recall.fact_call.enabled = false` → 退化为"带 summary 的历史" (仍优于纯平铺)
-   切换 `recall.strategy = "flat_history"` → 完全回退到现有 stable 行为
-   偏好注入在任何模式下都不受影响

---

## 十、与现有策略的关系

```
                    ┌───────────────────┐
                    │    配置选择         │
                    │ injection_strategy │
                    └────────┬──────────┘
                             │
            ┌────────────────┼────────────────┐
            │                │                │
       ┌────▼────┐    ┌─────▼─────┐    ┌─────▼─────┐
       │ stable  │    │ recall_v4 │    │full_attn  │
       │ (现有)   │    │ (新方案)   │    │ (研究)    │
       └────┬────┘    └─────┬─────┘    └─────┬─────┘
            │               │                │
  偏好: K/V       偏好: K/V       偏好: K/V
  历史: 平铺suffix  历史: 多信号召回  历史: K/V 注入
  fact call: ❌    → 逐消息阈值    fact call: ❌
                   → summary+trace
                   → fact call ✅
```

`recall_v4` 作为新的策略选项，与现有 `stable` 和 `full_attention` 并列。
