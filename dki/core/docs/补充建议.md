3.1 Phase 1：多信号召回 —— 可行，但有一个“隐性耦合风险”
✅ 正确的地方

三路信号（关键词 / 指代 / 向量）是工业标准

你没有迷信向量召回（这是对的）

“补充近期轮次”这个兜底非常重要

⚠️ 风险点（不改会出怪 bug）

关键词召回与向量召回的“排序融合”必须显式归一化

你现在写的是：

rank_by_relevance(merged)

但如果你没有：

对 TF-IDF 权重做 normalization

对 vector score 做 clip / sigmoid

会发生什么？

短 query + 强关键词 = keyword hits 完全压死语义相关但关键词弱的消息

👉 建议（这是必要的，不是优化）：

final_score =
w1 \* normalized_keyword_score

-   w2 \* normalized_vector_score
-   w3 \* recency_bonus

并且 w1 ≥ w2（你目标是事实准确，而不是语义联想）。

3.2 Phase 2：逐消息阈值 summary —— 这是你方案里最稳的一环

我明确说：

逐消息阈值 summary 比“整段 summary”安全一个数量级。

为什么？

trace_id 精确

function call 精确

offset/limit 有意义

你这里唯一要注意的一点是：

⚠️ Summary 的 epistemic marker 必须是结构化的，而不是纯文本修辞

你现在是：

-   本摘要可能缺失: 具体日期、价格

这是好的，但我建议你强制机器可读一点，例如：

[SUMMARY]
facts_covered: ["餐厅名称", "大致位置"]
facts_missing: ["营业时间", "价格", "预约方式"]
confidence: medium
trace_id: msg-005
[/SUMMARY]

否则在小模型（7B/8B）上，修辞提示会被忽略。

3.3 Phase 3：可信+推理限定提示 —— 必须承认一件残酷的事

我要实话说：

“不得基于 summary 推理”这句话，不是所有模型都会听。

尤其是：

小模型

温度 > 0.7

用户问题非常明确时

你已经做对的事

把 summary 明确标为非事实

给了 function call 路径

不强制立即拉取（避免 token 浪费）

你必须补的一道保险

👉 硬规则优于软规则：

在 PromptFormatter 里，建议增加一句强约束句式：

若在未调用 retrieve_fact 的情况下，
直接基于 summary 给出具体数值/时间/引用原话，
该回答被视为无效。

模型对“无效 / 错误 / 违规”这类词非常敏感。
