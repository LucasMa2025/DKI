# DKI - Dynamic KV Injection

> Attention-Level Memory Augmentation for Large Language Models

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[ç®€ä½“ä¸­æ–‡](README_CN.md) | English

## ğŸ“– Overview

DKI (Dynamic KV Injection) is a novel approach to memory augmentation for Large Language Models that injects memory content at the attention level rather than the token level.

Unlike traditional RAG (Retrieval-Augmented Generation) which consumes context window tokens, DKI computes Key-Value representations of memory content and injects them directly into the attention mechanism, **preserving the full context window for user input**.

### Key Features

-   **ğŸ§  Attention-Level Injection**: Memory injected via K/V, not prompt tokens
-   **ğŸšï¸ Memory Influence Scaling (MIS)**: Continuous Î± âˆˆ [0, 1] control
-   **ğŸ”„ Query-Conditioned Projection**: FiLM-style memory-centric transformation
-   **ğŸš¦ Dual-Factor Gating**: Uncertainty Ã— Relevance for smart injection decisions
-   **ğŸ’¾ Tiered KV Cache**: L1(GPU) â†’ L2(CPU) â†’ L3(SSD) â†’ L4(Recompute)
-   **ğŸ“Š Attention Budget Analysis**: Token vs Attention budget tracking
-   **ğŸ”Œ Multi-Engine Support**: vLLM, LLaMA, DeepSeek, GLM
-   **âœ… Graceful Degradation**: Î± â†’ 0 smoothly recovers vanilla LLM behavior

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Dynamic KV Injection System                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User Query                                                             â”‚
â”‚       â”‚                                                                 â”‚
â”‚       â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  1. Memory Router (FAISS + Sentence Embedding)                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  2. Dual-Factor Gating (Entropy Ã— Relevance)                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                    â–¼                       â–¼                            â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚           â”‚ Vanilla LLM  â”‚    â”‚ 3. Session KV Cache            â”‚        â”‚
â”‚           â”‚ (fallback)   â”‚    â”‚ + Query-Conditioned Projection â”‚        â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                             â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  4. Memory Influence Scaling (Î± control)                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  5. LLM with KV Injection â†’ Generate Response                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
cd DKI

# Setup (creates venv, installs dependencies, initializes DB)
# Windows:
scripts\setup.bat

# Linux/Mac:
chmod +x scripts/*.sh
./scripts/setup.sh
```

### Start Web UI

```bash
# Windows:
scripts\start.bat web

# Linux/Mac:
./scripts/start.sh web
```

Open http://localhost:8080 in your browser.

### Python Usage

```python
from dki import DKISystem

# Initialize
dki = DKISystem()

# Add memories
dki.add_memory(
    session_id="user_001",
    content="User prefers vegetarian food and is allergic to seafood"
)
dki.add_memory(
    session_id="user_001",
    content="User lives in Beijing and enjoys hiking"
)

# Chat with memory injection
response = dki.chat(
    query="Recommend a restaurant for lunch",
    session_id="user_001"
)

print(response.text)
# Output considers vegetarian preference without explicit prompt mention

print(f"Alpha: {response.gating_decision.alpha}")
print(f"Memories used: {len(response.memories_used)}")
print(f"Latency: {response.latency_ms}ms")
```

## ğŸ“ Project Structure

```
DKI/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml           # Main configuration
â”œâ”€â”€ dki/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ dki_system.py     # Main DKI system
â”‚   â”‚   â”œâ”€â”€ rag_system.py     # RAG baseline
â”‚   â”‚   â”œâ”€â”€ memory_router.py  # FAISS-based retrieval
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ architecture.py   # Architecture documentation
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ memory_influence_scaling.py
â”‚   â”‚       â”œâ”€â”€ query_conditioned_projection.py
â”‚   â”‚       â”œâ”€â”€ dual_factor_gating.py
â”‚   â”‚       â”œâ”€â”€ session_kv_cache.py
â”‚   â”‚       â”œâ”€â”€ tiered_kv_cache.py    # L1/L2/L3/L4 memory hierarchy
â”‚   â”‚       â”œâ”€â”€ attention_budget.py   # Budget analysis
â”‚   â”‚       â””â”€â”€ position_remapper.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ factory.py        # Model factory
â”‚   â”‚   â”œâ”€â”€ base.py           # Base adapter
â”‚   â”‚   â”œâ”€â”€ vllm_adapter.py
â”‚   â”‚   â”œâ”€â”€ llama_adapter.py
â”‚   â”‚   â”œâ”€â”€ deepseek_adapter.py
â”‚   â”‚   â””â”€â”€ glm_adapter.py
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py         # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ connection.py     # DB connection manager
â”‚   â”‚   â””â”€â”€ repository.py     # Repository pattern
â”‚   â”œâ”€â”€ experiment/
â”‚   â”‚   â”œâ”€â”€ runner.py         # Experiment runner
â”‚   â”‚   â”œâ”€â”€ metrics.py        # Evaluation metrics
â”‚   â”‚   â””â”€â”€ data_generator.py # Test data generation
â”‚   â””â”€â”€ web/
â”‚       â””â”€â”€ app.py            # FastAPI + Web UI
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.sql           # Database schema
â”‚   â”œâ”€â”€ setup.bat/.sh         # Setup scripts
â”‚   â””â”€â”€ start.bat/.sh         # Start scripts
â”œâ”€â”€ data/                      # Experiment data
â”œâ”€â”€ experiment_results/        # Experiment outputs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

Edit `config/config.yaml`:

```yaml
# Model Engine
model:
    default_engine: "vllm" # vllm, llama, deepseek, glm
    engines:
        vllm:
            model_name: "Qwen/Qwen2-7B-Instruct"
            tensor_parallel_size: 1

# DKI Settings
dki:
    gating:
        entropy_threshold: 0.5
        relevance_threshold: 0.7
    cache:
        max_size: 100
        strategy: "weighted" # lru, lfu, weighted

# RAG Settings
rag:
    top_k: 5
    similarity_threshold: 0.5
```

## ğŸ“Š Experiments

### Generate Test Data

```bash
python -m dki.experiment.data_generator
```

### Run Comparison Experiment

```python
from dki.experiment.runner import ExperimentRunner, ExperimentConfig

runner = ExperimentRunner()
config = ExperimentConfig(
    name="DKI vs RAG Comparison",
    modes=["dki", "rag", "baseline"],
    datasets=["persona_chat", "memory_qa"],
    max_samples=100
)

results = runner.run_experiment(config)
```

### Alpha Sensitivity Analysis

```python
results = runner.run_alpha_sensitivity(
    alpha_values=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
)
```

## ğŸ“ˆ API Reference

### REST API

| Endpoint                     | Method | Description                |
| ---------------------------- | ------ | -------------------------- |
| `/api/chat`                  | POST   | Chat with DKI/RAG/Baseline |
| `/api/memory`                | POST   | Add memory                 |
| `/api/memories/{session_id}` | GET    | Get session memories       |
| `/api/search`                | POST   | Search memories            |
| `/api/stats`                 | GET    | Get system statistics      |
| `/api/experiment/run`        | POST   | Run experiment             |

### Chat Request

```json
{
    "query": "Recommend a restaurant",
    "session_id": "user_001",
    "mode": "dki",
    "force_alpha": 0.7,
    "max_new_tokens": 256,
    "temperature": 0.7
}
```

### Chat Response

```json
{
    "response": "Based on your preference for vegetarian food...",
    "mode": "dki",
    "session_id": "user_001",
    "latency_ms": 156.3,
    "memories_used": [...],
    "alpha": 0.72,
    "cache_hit": true
}
```

## ğŸ”¬ Research Background

DKI addresses a fundamental limitation of RAG: retrieved content consumes context window capacity, creating a trade-off between memory content and user input space.

**RAG Paradigm:**

```
[Retrieved Content (consumed)] [User Input (remaining)]
Token Budget: B_t^used = n_m + n_u
Attention Budget: B_a = (n_m + n_u)Â²
```

**DKI Paradigm:**

```
[User Input (full budget available)]
     â†‘ Memory injected via K/V (not in token budget)
Token Budget: B_t^used = n_u (memory free!)
Attention Budget: B_a = n_u Ã— (n_m + n_u)
```

### DKI vs Cross-Attention

DKI is NOT equivalent to Cross-Attention:

| Feature       | DKI                  | Cross-Attention                          |
| ------------- | -------------------- | ---------------------------------------- |
| Parameters    | Reuses W_k, W_v      | Separate W_q^cross, W_k^cross, W_v^cross |
| Training      | Training-free        | Requires training                        |
| Architecture  | No modification      | Dedicated layers                         |
| Compatibility | Any decoder-only LLM | Encoder-decoder only                     |
| Control       | Continuous Î±         | Learned weights                          |

### Design Invariants

1. **Storage Model-Agnostic**: Store only original text + routing vectors
2. **Injection Model-Consistent**: K/V computed with target model parameters
3. **Session Cache Disposable**: Inference-time enhancement, not persistent
4. **Graceful Degradation**: Î± â†’ 0 falls back to vanilla LLM
5. **Audit Logging**: All injection decisions logged for compliance

### Memory Hierarchy (Tiered KV Cache)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L1: GPU HBM (Hot)     - Uncompressed FP16         â”‚
â”‚  L2: CPU RAM (Warm)    - Compressed (2-4Ã—)         â”‚
â”‚  L3: NVMe SSD (Cold)   - Quantized INT8 (8Ã—)       â”‚
â”‚  L4: Text Only         - Recompute on demand       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Memory footprint scales with ACTIVE memories, not total corpus size.

## ğŸ“„ Related Papers

This project is based on the paper "Dynamic KV Injection: Attention-Level Memory Augmentation for Large Language Models".

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines first.

---

**DKI** - Rethinking Memory Augmentation at the Attention Level
